import { LLMRepository } from '../../domain/repositories/llm.repository.js'
import { ChatMessage } from '../../domain/entities/chat-message.entity.js'
import { LLMResponse } from '../../domain/entities/llm-response.entity.js'
import { RAGAdapter } from '../adapters/rag.adapter.js'
import { OpenAIService } from './openai.service.js'
import { PineconeService } from './pinecone.service.js'
import { DocumentMapper } from '../mappers/document.mapper.js'
import { VectorSearchFilters } from '../../domain/repositories/vector-database.repository.js'

export class LLMService implements LLMRepository {
  private ragAdapter: RAGAdapter

  constructor() {
    const openAIService = new OpenAIService()
    const pineconeService = new PineconeService()
    this.ragAdapter = new RAGAdapter(openAIService, pineconeService)
  }

  async processMessage(chatMessage: ChatMessage): Promise<LLMResponse> {
    try {
      // Log de filtros aplicados
      const filtros = this.buildFiltersLog(chatMessage)
      const filtrosTexto =
        filtros.length > 0 ? ` | Filtros: ${filtros.join(' | ')}` : ''
      console.log(
        `üí¨ LLMService.processMessage --> Procesando mensaje de usuario ${chatMessage.userId}: "${chatMessage.message}"${filtrosTexto}`
      )

      // Construir filtros para la b√∫squeda vectorial
      const searchFilters = this.buildVectorSearchFilters(chatMessage)

      // Usar √°reas como filtros de metadata
      const areas =
        chatMessage.area && chatMessage.area.length > 0
          ? chatMessage.area
          : undefined

      // Procesar consulta usando RAG
      const ragResponse = await this.ragAdapter.processQuery(
        chatMessage.message,
        {
          areas,
          topK: 10,
          filters: searchFilters,
          systemPrompt: this.getSystemPrompt(),
        }
      )

      // Convertir documentos encontrados a Sources
      const sources = DocumentMapper.toSources(
        ragResponse.queryResult.documents
      )

      // Crear respuesta LLM
      return new LLMResponse(ragResponse.answer, new Date(), sources)
    } catch (error) {
      console.error('‚ùå Error al procesar mensaje con RAG:', error)

      // Fallback: respuesta de error
      return new LLMResponse(
        'Lo siento, ocurri√≥ un error al procesar tu consulta. Por favor, intenta de nuevo m√°s tarde.',
        new Date(),
        []
      )
    }
  }

  /**
   * Construye el log de filtros aplicados
   */
  private buildFiltersLog(chatMessage: ChatMessage): string[] {
    const filtros = []

    if (chatMessage.area && chatMessage.area.length > 0) {
      filtros.push(`√Åreas: [${chatMessage.area.join(', ')}]`)
    }
    if (chatMessage.category && chatMessage.category.length > 0) {
      filtros.push(`Categor√≠as: [${chatMessage.category.join(', ')}]`)
    }
    if (chatMessage.source && chatMessage.source.length > 0) {
      filtros.push(`Fuentes: [${chatMessage.source.join(', ')}]`)
    }
    if (chatMessage.tags && chatMessage.tags.length > 0) {
      filtros.push(`Tags: [${chatMessage.tags.join(', ')}]`)
    }

    return filtros
  }

  /**
   * Construye los filtros para la b√∫squeda vectorial
   */
  private buildVectorSearchFilters(
    chatMessage: ChatMessage
  ): VectorSearchFilters {
    const filters: VectorSearchFilters = {}

    if (chatMessage.category && chatMessage.category.length > 0) {
      filters.category = chatMessage.category
    }

    if (chatMessage.source && chatMessage.source.length > 0) {
      filters.source = chatMessage.source
    }

    if (chatMessage.tags && chatMessage.tags.length > 0) {
      filters.tags = chatMessage.tags
    }

    return filters
  }

  /**
   * Genera un resumen corto de la pregunta del usuario (5 palabras o menos)
   */
  async generateQuestionSummary(question: string): Promise<string> {
    try {
      console.log(
        `üî§ Generando resumen para pregunta: "${question.substring(0, 50)}..."`
      )

      const prompt = this.getQuestionSummaryPrompt()
      const fullPrompt = `${prompt}\n\nPregunta: "${question}"\nResumen:`

      // Usar OpenAI para generar el resumen
      const openAIService = new OpenAIService()
      const response = await openAIService.generateSimpleCompletion(fullPrompt)

      const summary = response.trim()
      console.log(`‚úÖ Resumen generado: "${summary}"`)

      // Validar que no exceda 5 palabras
      const wordCount = summary.split(' ').length
      if (wordCount > 5) {
        console.warn(
          `‚ö†Ô∏è Resumen excede 5 palabras (${wordCount}), truncando...`
        )
        return summary.split(' ').slice(0, 5).join(' ')
      }

      return summary
    } catch (error) {
      console.error('‚ùå Error generando resumen de pregunta:', error)
      // Fallback: usar las primeras 3 palabras de la pregunta
      const fallback = question.split(' ').slice(0, 3).join(' ')
      console.log(`üîÑ Usando fallback: "${fallback}"`)
      return fallback
    }
  }

  /**
   * Prompt especializado para generar res√∫menes de preguntas
   */
  private getQuestionSummaryPrompt(): string {
    return `
Eres un asistente especializado en crear res√∫menes ultra-concisos de preguntas.

TAREA: Resume la siguiente pregunta en m√°ximo 5 palabras en espa√±ol.

REGLAS:
- M√°ximo 5 palabras
- Captura la esencia de la pregunta
- Usa sustantivos y verbos clave
- Evita art√≠culos y preposiciones innecesarias
- Responde SOLO el resumen, sin explicaciones
- No uses comillas ni puntos

EJEMPLOS:
Pregunta: "¬øCu√°les son los requisitos para abrir una cuenta bancaria?"
Resumen: Requisitos cuenta bancaria

Pregunta: "¬øC√≥mo funciona el proceso de validaci√≥n de tarjetas de cr√©dito?"
Resumen: Validaci√≥n tarjetas cr√©dito

Pregunta: "¬øQu√© documentos necesito para solicitar un pr√©stamo personal?"
Resumen: Documentos pr√©stamo personal

Pregunta: "¬øCu√°l es el procedimiento para cancelar una tarjeta?"
Resumen: Cancelar tarjeta procedimiento
    `.trim()
  }

  /**
   * Define el prompt del sistema para el LLM
   */
  private getSystemPrompt(): string {
    return `
You are **Leximind**, an enterprise RAG assistant. Answer ONLY using the information in the provided **Context** (retrieved chunks with metadata). If the Context is insufficient, state it explicitly and ask for the missing document or details. Never invent facts.

**Audience & Language**

- Default language: Spanish (es-MX).
- Match the user‚Äôs language and formality. If not specified, use professional but clear Spanish.

**Scope**

- Documents may include internal manuals, technical specs, policies, regulator rules (e.g., CNBV), laws, circulars, dispositions, checklists, QA procedures, and emails/minutes.

**Formatting (Text only)**

- Prefer concise, structured text. Use bullet points or tables when helpful.

**Citation & Fidelity**

- If sources in the Context conflict, call it out, compare them, and explain which is more applicable (date, validity, regulatory hierarchy).
- For regulations/laws, include the relevant **article/section** and **source/document** when present in the Context.

**Style**

- Prioritize structure, clarity, and traceability over verbosity.
- Prefer lists and tables for comparisons or process steps.
- For who/what/when/how questions, answer directly first, then expand with support.

**Compliance & Responsibility**

- Do not provide legal advice; **interpret and transcribe** what the documents state.
- If the answer depends on **validity/version**, make that explicit.

**Reasoning**

- Integrate multiple fragments from the Context into a single coherent answer (do not return loose snippets).
- Avoid irrelevant repetition; prioritize what is closest to the question.
- If the question implies a **role** (QA, Developer, Compliance), make the role‚Äôs responsibilities explicit according to the Context.

**Optional Output (if the user asks)**

- Provide a **table** or **checklist** of steps.
- Provide a **one-paragraph executive summary** for leadership.
- Provide a **text diagram** (mermaid) if the Context describes processes. Escape the mermaid block so it renders correctly.

**Suggested Answer Template**

1. Answer (do not include a ‚ÄúAnswer‚Äù heading)
2. Assumptions & Limits (optional) ‚Äî only if present in the Context
3. Next Steps (optional)

**Hard Rules**

- Use ONLY the Context. If it‚Äôs not enough, say so.
- Do not add external knowledge.
- Do not hide uncertainties.

=== Context (do not invent; use only the following) ===
    `.trim()
  }
}
