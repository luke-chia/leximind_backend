{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1662e0a-5fe3-4f64-9cc6-b61f6ec3d7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OPENAI_API_KEY', 'PINECONE_API_KEY', 'PINECONE_ENV']\n",
      "OPENAI_API_KEY: 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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv, dotenv_values\n",
    "import os\n",
    "\n",
    "load_dotenv(find_dotenv())  # read local .env file\n",
    "\n",
    "env_file_keys = list(dotenv_values(find_dotenv()).keys())\n",
    "print(env_file_keys)\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "print('OPENAI_API_KEY:', api_key if api_key else 'No encontrada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3d935da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/superchia/Documents/Personal/IA/python/hello-notebook/hellou/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/var/folders/dv/vcv0m0g13x714jf4rhn_sljh0000gn/T/ipykernel_45213/2951536551.py:4: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a4145b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINECONE_API_KEY: pcsk_2wmgPR_CgVgRjpcMhmbbuXP6ptQcCFPm8ySFQ7XGNRChYNKmm4ePyvyiTEtg4qZ7FtsgNS\n",
      "Pinecone inicializado correctamente con API 6.x\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())  # read local .env file\n",
    "\n",
    "# Verificamos que las variables de entorno est√©n definidas\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "print(\"PINECONE_API_KEY:\", api_key if api_key else \"No encontrada\")\n",
    "\n",
    "# Con pinecone-client 6.x, usamos la nueva sintaxis\n",
    "if api_key:\n",
    "    try:\n",
    "        # Inicializar con la nueva API\n",
    "        pc = Pinecone(api_key=api_key)\n",
    "        print(\"Pinecone inicializado correctamente con API 6.x\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al inicializar Pinecone: {e}\")\n",
    "else:\n",
    "    print(\"Error: Falta la variable de entorno PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013bf55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√çndices disponibles: [{\n",
      "    \"name\": \"efisys-wiki-knowledge\",\n",
      "    \"metric\": \"cosine\",\n",
      "    \"host\": \"efisys-wiki-knowledge-3se3hjl.svc.aped-4627-b74a.pinecone.io\",\n",
      "    \"spec\": {\n",
      "        \"serverless\": {\n",
      "            \"cloud\": \"aws\",\n",
      "            \"region\": \"us-east-1\"\n",
      "        }\n",
      "    },\n",
      "    \"status\": {\n",
      "        \"ready\": true,\n",
      "        \"state\": \"Ready\"\n",
      "    },\n",
      "    \"vector_type\": \"dense\",\n",
      "    \"dimension\": 1536,\n",
      "    \"deletion_protection\": \"disabled\",\n",
      "    \"tags\": null\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "index_name = \"efisys-wiki-knowledge\"\n",
    "try:\n",
    "    # Lista los √≠ndices disponibles con la nueva API\n",
    "    indexes = pc.list_indexes()\n",
    "    print(\"√çndices disponibles:\", indexes)\n",
    "except Exception as e:\n",
    "    print(f\"Error al listar √≠ndices: {e}\")\n",
    "    print(\"Tipo de error:\", type(e).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fb9a8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√çndice 'efisys-wiki-knowledge' ya existe.\n"
     ]
    }
   ],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "index_name = \"efisys-wiki-knowledge\"\n",
    "try:\n",
    "    # Lista √≠ndices existentes\n",
    "    existing_indexes = [idx.name for idx in pc.list_indexes()]\n",
    "\n",
    "    if index_name not in existing_indexes:\n",
    "        print(f\"√çndice '{index_name}' no existe. Creando con serverless...\")\n",
    "        # Crear √≠ndice serverless\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=1536,  # Dimensi√≥n para text-embedding-3-small\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(\n",
    "                cloud='aws',\n",
    "                region='us-east-1'\n",
    "            )\n",
    "        )\n",
    "        print(f\"√çndice '{index_name}' creado exitosamente.\")\n",
    "    else:\n",
    "        print(f\"√çndice '{index_name}' ya existe.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al verificar/crear √≠ndice: {e}\")\n",
    "    print(f\"Tipo de error: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7b00c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para cargar y vectorizar PDFs con informaci√≥n de p√°gina\n",
    "import PyPDF2\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "import os\n",
    "\n",
    "def vectorizar_pdf(nombre_pdf, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Funci√≥n que recibe el nombre de un archivo PDF, lo carga, procesa y vectoriza\n",
    "    manteniendo informaci√≥n precisa de p√°ginas en los metadatos.\n",
    "\n",
    "    Par√°metros:\n",
    "    - nombre_pdf (str): Ruta al archivo PDF\n",
    "    - chunk_size (int): Tama√±o de cada fragmento de texto\n",
    "    - chunk_overlap (int): Superposici√≥n entre fragmentos\n",
    "\n",
    "    Retorna:\n",
    "    - dict: Diccionario con los documentos vectorizados y metadatos incluyendo p√°gina\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # 1. Verificar que el archivo existe\n",
    "        if not os.path.exists(nombre_pdf):\n",
    "            raise FileNotFoundError(f\"El archivo {nombre_pdf} no existe\")\n",
    "\n",
    "        # 2. Extraer texto del PDF p√°gina por p√°gina\n",
    "        print(f\"üìÑ Cargando PDF: {nombre_pdf}\")\n",
    "\n",
    "        documentos_por_pagina = []\n",
    "\n",
    "        with open(nombre_pdf, 'rb') as archivo:\n",
    "            lector_pdf = PyPDF2.PdfReader(archivo)\n",
    "            num_paginas = len(lector_pdf.pages)\n",
    "\n",
    "            for i, pagina in enumerate(lector_pdf.pages):\n",
    "                texto_pagina = pagina.extract_text()\n",
    "\n",
    "                # Crear documento por p√°gina con metadatos\n",
    "                if texto_pagina.strip():  # Solo si la p√°gina tiene contenido\n",
    "                    doc_pagina = Document(\n",
    "                        page_content=texto_pagina,\n",
    "                        metadata={\n",
    "                            \"source\": os.path.basename(nombre_pdf),\n",
    "                            \"page\": i + 1,  # N√∫mero de p√°gina (1-indexado)\n",
    "                            \"page_number\": i + 1,  # Campo adicional por compatibilidad\n",
    "                            \"total_pages\": num_paginas,\n",
    "                            \"file_path\": nombre_pdf\n",
    "                        }\n",
    "                    )\n",
    "                    documentos_por_pagina.append(doc_pagina)\n",
    "\n",
    "        print(f\"‚úÖ PDF cargado exitosamente. P√°ginas: {num_paginas}\")\n",
    "        print(f\"ÔøΩ P√°ginas con contenido: {len(documentos_por_pagina)}\")\n",
    "\n",
    "        # 3. Dividir el texto en fragmentos manteniendo informaci√≥n de p√°gina\n",
    "        print(\"üî™ Dividiendo texto en fragmentos por p√°gina...\")\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "        )\n",
    "\n",
    "        todos_los_fragmentos = []\n",
    "        total_caracteres = 0\n",
    "\n",
    "        for doc_pagina in documentos_por_pagina:\n",
    "            total_caracteres += len(doc_pagina.page_content)\n",
    "\n",
    "            # Dividir cada p√°gina en fragmentos\n",
    "            fragmentos_pagina = text_splitter.split_text(doc_pagina.page_content)\n",
    "\n",
    "            for j, fragmento in enumerate(fragmentos_pagina):\n",
    "                # Crear documento fragmento con informaci√≥n de p√°gina precisa\n",
    "                doc_fragmento = Document(\n",
    "                    page_content=fragmento,\n",
    "                    metadata={\n",
    "                        **doc_pagina.metadata,  # Mantener todos los metadatos de p√°gina\n",
    "                        \"chunk_in_page\": j,  # N√∫mero de chunk dentro de la p√°gina\n",
    "                        \"chunk_id\": f\"page_{doc_pagina.metadata['page']}_chunk_{j}\",\n",
    "                        \"total_chunks_in_page\": len(fragmentos_pagina)\n",
    "                    }\n",
    "                )\n",
    "                todos_los_fragmentos.append(doc_fragmento)\n",
    "\n",
    "        print(f\"üìä Caracteres extra√≠dos: {total_caracteres}\")\n",
    "        print(f\"üìù Texto dividido en {len(todos_los_fragmentos)} fragmentos\")\n",
    "\n",
    "        # 4. Generar embeddings\n",
    "        print(\"ü§ñ Generando embeddings con text-embedding-3-small...\")\n",
    "        embeddings_model = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "\n",
    "        # Generar embeddings para cada fragmento\n",
    "        vectores = []\n",
    "        textos = []\n",
    "        metadatos = []\n",
    "\n",
    "        for i, doc in enumerate(todos_los_fragmentos):\n",
    "            # Generar embedding\n",
    "            embedding = embeddings_model.embed_query(doc.page_content)\n",
    "\n",
    "            # Preparar datos para base de datos vectorial con informaci√≥n de p√°gina\n",
    "            vector_data = {\n",
    "                \"id\": f\"{os.path.basename(nombre_pdf).replace('.pdf', '')}_page_{doc.metadata['page']}_chunk_{doc.metadata['chunk_in_page']}\",\n",
    "                \"values\": embedding,\n",
    "                \"metadata\": {\n",
    "                    # Informaci√≥n del documento\n",
    "                    \"source\": doc.metadata[\"source\"],\n",
    "                    \"file_path\": doc.metadata[\"file_path\"],\n",
    "\n",
    "                    # Informaci√≥n de p√°gina (m√∫ltiples campos para compatibilidad)\n",
    "                    \"page\": doc.metadata[\"page\"],\n",
    "                    \"page_number\": doc.metadata[\"page_number\"],\n",
    "                    \"total_pages\": doc.metadata[\"total_pages\"],\n",
    "\n",
    "                    # Informaci√≥n de fragmento\n",
    "                    \"chunk_id\": doc.metadata[\"chunk_id\"],\n",
    "                    \"chunk_in_page\": doc.metadata[\"chunk_in_page\"],\n",
    "                    \"total_chunks_in_page\": doc.metadata[\"total_chunks_in_page\"],\n",
    "                    \"global_chunk_id\": i,  # ID del chunk a nivel global\n",
    "                    \"total_chunks\": len(todos_los_fragmentos),\n",
    "\n",
    "                    # Contenido del texto (truncado para metadatos)\n",
    "                    \"text\": doc.page_content[:500] + \"...\" if len(doc.page_content) > 500 else doc.page_content\n",
    "                }\n",
    "            }\n",
    "\n",
    "            vectores.append(vector_data)\n",
    "            textos.append(doc.page_content)\n",
    "            metadatos.append(doc.metadata)\n",
    "\n",
    "        print(f\"‚ú® Embeddings generados exitosamente para {len(vectores)} fragmentos\")\n",
    "\n",
    "        # 5. Preparar resultado con estad√≠sticas por p√°gina\n",
    "        paginas_procesadas = {}\n",
    "        for doc in todos_los_fragmentos:\n",
    "            pagina = doc.metadata['page']\n",
    "            if pagina not in paginas_procesadas:\n",
    "                paginas_procesadas[pagina] = 0\n",
    "            paginas_procesadas[pagina] += 1\n",
    "\n",
    "        resultado = {\n",
    "            \"archivo\": nombre_pdf,\n",
    "            \"num_paginas\": num_paginas,\n",
    "            \"num_fragmentos\": len(todos_los_fragmentos),\n",
    "            \"vectores\": vectores,  # Listos para insertar en Pinecone\n",
    "            \"documentos\": todos_los_fragmentos,  # Documentos originales\n",
    "            \"textos\": textos,\n",
    "            \"metadatos\": metadatos,\n",
    "            \"embeddings_model\": embeddings_model,\n",
    "            \"dimension\": len(vectores[0][\"values\"]) if vectores else 0,\n",
    "            \"estadisticas_paginas\": paginas_procesadas  # Fragmentos por p√°gina\n",
    "        }\n",
    "\n",
    "        print(\"üéâ PDF vectorizado exitosamente con informaci√≥n de p√°ginas!\")\n",
    "        print(f\"üìè Dimensi√≥n de vectores: {resultado['dimension']}\")\n",
    "\n",
    "        # Mostrar resumen de p√°ginas procesadas\n",
    "        print(f\"üìÑ Estad√≠sticas por p√°gina:\")\n",
    "        for pagina in sorted(paginas_procesadas.keys())[:5]:  # Mostrar solo las primeras 5\n",
    "            print(f\"   P√°gina {pagina}: {paginas_procesadas[pagina]} fragmentos\")\n",
    "        if len(paginas_procesadas) > 5:\n",
    "            print(f\"   ... y {len(paginas_procesadas) - 5} p√°ginas m√°s\")\n",
    "\n",
    "        return resultado\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al vectorizar PDF: {e}\")\n",
    "        print(f\"Tipo de error: {type(e).__name__}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79f1cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para cargar y vectorizar PDFs con informaci√≥n de p√°gina\n",
    "import PyPDF2\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "import os\n",
    "\n",
    "# Funci√≥n auxiliar para subir vectores a Pinecone (sin cambios)\n",
    "def subir_vectores_a_pinecone(resultado_vectorizacion, pc, index_name, namespace=\"default\"):\n",
    "    \"\"\"\n",
    "    Funci√≥n auxiliar para subir los vectores generados a Pinecone\n",
    "\n",
    "    Par√°metros:\n",
    "    - resultado_vectorizacion: Resultado de la funci√≥n vectorizar_pdf\n",
    "    - pc: Cliente de Pinecone inicializado\n",
    "    - index_name: Nombre del √≠ndice en Pinecone\n",
    "    - namespace: Namespace donde guardar los vectores\n",
    "    \"\"\"\n",
    "\n",
    "    if not resultado_vectorizacion:\n",
    "        print(\"‚ùå No hay datos para subir\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        index = pc.Index(index_name)\n",
    "\n",
    "        # Subir vectores en lotes para mejor rendimiento\n",
    "        vectores = resultado_vectorizacion[\"vectores\"]\n",
    "        batch_size = 100\n",
    "\n",
    "        print(f\"‚¨ÜÔ∏è Subiendo {len(vectores)} vectores a Pinecone...\")\n",
    "        print(f\"üìÑ Cada vector incluye informaci√≥n de p√°gina en metadatos\")\n",
    "\n",
    "        for i in range(0, len(vectores), batch_size):\n",
    "            batch = vectores[i:i + batch_size]\n",
    "            response = index.upsert(vectors=batch, namespace=namespace)\n",
    "            print(f\"‚úÖ Lote {i//batch_size + 1} subido: {response}\")\n",
    "\n",
    "        # Verificar estad√≠sticas\n",
    "        stats = index.describe_index_stats()\n",
    "        print(f\"üìä Estad√≠sticas del √≠ndice: {stats}\")\n",
    "\n",
    "        # Mostrar ejemplo de metadatos del primer vector\n",
    "        if vectores:\n",
    "            print(f\"üìã Ejemplo de metadatos incluidos:\")\n",
    "            ejemplo = vectores[0][\"metadata\"]\n",
    "            print(f\"   üìÑ P√°gina: {ejemplo.get('page', 'N/A')}\")\n",
    "            print(f\"   üî¢ Chunk en p√°gina: {ejemplo.get('chunk_in_page', 'N/A')}\")\n",
    "            print(f\"   üÜî ID: {ejemplo.get('chunk_id', 'N/A')}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al subir vectores: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3763d57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Re-vectorizando PDF con informaci√≥n mejorada de p√°ginas...\n",
      "============================================================\n",
      "üìÑ Cargando PDF: ../media/Estandares_Fabrica.pdf\n",
      "‚úÖ PDF cargado exitosamente. P√°ginas: 73\n",
      "ÔøΩ P√°ginas con contenido: 73\n",
      "üî™ Dividiendo texto en fragmentos por p√°gina...\n",
      "üìä Caracteres extra√≠dos: 118654\n",
      "üìù Texto dividido en 215 fragmentos\n",
      "ü§ñ Generando embeddings con text-embedding-3-small...\n",
      "‚ú® Embeddings generados exitosamente para 215 fragmentos\n",
      "üéâ PDF vectorizado exitosamente con informaci√≥n de p√°ginas!\n",
      "üìè Dimensi√≥n de vectores: 1536\n",
      "üìÑ Estad√≠sticas por p√°gina:\n",
      "   P√°gina 1: 1 fragmentos\n",
      "   P√°gina 2: 4 fragmentos\n",
      "   P√°gina 3: 1 fragmentos\n",
      "   P√°gina 4: 1 fragmentos\n",
      "   P√°gina 5: 3 fragmentos\n",
      "   ... y 68 p√°ginas m√°s\n",
      "\n",
      "‚úÖ PDF vectorizado con p√°ginas:\n",
      "   üìÑ Archivo: ../media/Estandares_Fabrica.pdf\n",
      "   üìö P√°ginas totales: 73\n",
      "   üìù Fragmentos generados: 215\n",
      "   üìè Dimensi√≥n de vectores: 1536\n",
      "\n",
      "üìä Estad√≠sticas de fragmentaci√≥n:\n",
      "   üìÑ P√°ginas procesadas: 73\n",
      "   üî¢ Promedio fragmentos/p√°gina: 2.9\n",
      "   üìã Distribuci√≥n (primeras 10 p√°ginas):\n",
      "      P√°gina 1: 1 fragmentos\n",
      "      P√°gina 2: 4 fragmentos\n",
      "      P√°gina 3: 1 fragmentos\n",
      "      P√°gina 4: 1 fragmentos\n",
      "      P√°gina 5: 3 fragmentos\n",
      "      P√°gina 6: 4 fragmentos\n",
      "      P√°gina 7: 3 fragmentos\n",
      "      P√°gina 8: 4 fragmentos\n",
      "      P√°gina 9: 3 fragmentos\n",
      "      P√°gina 10: 4 fragmentos\n",
      "\n",
      "üîç Ejemplo de metadatos mejorados:\n",
      "   üÜî ID: Estandares_Fabrica_page_1_chunk_0\n",
      "   üìÑ P√°gina: 1\n",
      "   üî¢ Chunk en p√°gina: 0\n",
      "   üìä Total p√°ginas: 73\n",
      "   üìù Fragmento de texto: 1   \n",
      "Est√°ndares de la F√°brica de Software \n",
      "        EST√ÅNDARES DE  LA F√ÅBRICA DE SOFTWARE...\n",
      "\n",
      "üí° Los vectores ahora incluyen informaci√≥n precisa de p√°ginas!\n",
      "üí° Sube los vectores a Pinecone para usar la nueva funcionalidad\n"
     ]
    }
   ],
   "source": [
    "# üìÑ Ejemplo de uso mejorado - Vectorizaci√≥n con informaci√≥n de p√°gina\n",
    "\n",
    "# Ruta al archivo PDF que quieres vectorizar (ruta desde la carpeta src)\n",
    "ruta_pdf = \"../media/Estandares_Fabrica.pdf\"\n",
    "\n",
    "print(\"üîÑ Re-vectorizando PDF con informaci√≥n mejorada de p√°ginas...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Vectorizar el PDF con la nueva funci√≥n mejorada\n",
    "resultado = vectorizar_pdf(\n",
    "    nombre_pdf=ruta_pdf,\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "if resultado:\n",
    "    print(f\"\\n‚úÖ PDF vectorizado con p√°ginas:\")\n",
    "    print(f\"   üìÑ Archivo: {resultado['archivo']}\")\n",
    "    print(f\"   üìö P√°ginas totales: {resultado['num_paginas']}\")\n",
    "    print(f\"   üìù Fragmentos generados: {resultado['num_fragmentos']}\")\n",
    "    print(f\"   üìè Dimensi√≥n de vectores: {resultado['dimension']}\")\n",
    "\n",
    "    # Mostrar estad√≠sticas detalladas\n",
    "    if 'estadisticas_paginas' in resultado:\n",
    "        print(f\"\\nüìä Estad√≠sticas de fragmentaci√≥n:\")\n",
    "        stats = resultado['estadisticas_paginas']\n",
    "        total_paginas = len(stats)\n",
    "        promedio_chunks = sum(stats.values()) / total_paginas if total_paginas > 0 else 0\n",
    "        print(f\"   üìÑ P√°ginas procesadas: {total_paginas}\")\n",
    "        print(f\"   üî¢ Promedio fragmentos/p√°gina: {promedio_chunks:.1f}\")\n",
    "\n",
    "        # Mostrar distribuci√≥n de fragmentos por p√°gina (primeras 10)\n",
    "        print(f\"   üìã Distribuci√≥n (primeras 10 p√°ginas):\")\n",
    "        for pagina in sorted(stats.keys())[:10]:\n",
    "            print(f\"      P√°gina {pagina}: {stats[pagina]} fragmentos\")\n",
    "\n",
    "    # Mostrar ejemplo de metadatos mejorados\n",
    "    if resultado['vectores']:\n",
    "        print(f\"\\nüîç Ejemplo de metadatos mejorados:\")\n",
    "        ejemplo_vector = resultado['vectores'][0]\n",
    "        metadata = ejemplo_vector['metadata']\n",
    "        print(f\"   üÜî ID: {ejemplo_vector['id']}\")\n",
    "        print(f\"   üìÑ P√°gina: {metadata.get('page', 'N/A')}\")\n",
    "        print(f\"   üî¢ Chunk en p√°gina: {metadata.get('chunk_in_page', 'N/A')}\")\n",
    "        print(f\"   üìä Total p√°ginas: {metadata.get('total_pages', 'N/A')}\")\n",
    "        print(f\"   üìù Fragmento de texto: {metadata.get('text', 'N/A')[:100]}...\")\n",
    "\n",
    "    print(f\"\\nüí° Los vectores ahora incluyen informaci√≥n precisa de p√°ginas!\")\n",
    "    print(f\"üí° Sube los vectores a Pinecone para usar la nueva funcionalidad\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Error al vectorizar el PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "566d867f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨ÜÔ∏è Subiendo 215 vectores a Pinecone...\n",
      "üìÑ Cada vector incluye informaci√≥n de p√°gina en metadatos\n",
      "‚úÖ Lote 1 subido: {'upserted_count': 100}\n",
      "‚úÖ Lote 2 subido: {'upserted_count': 100}\n",
      "‚úÖ Lote 3 subido: {'upserted_count': 15}\n",
      "üìä Estad√≠sticas del √≠ndice: {'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0,\n",
      " 'vector_type': 'dense'}\n",
      "üìã Ejemplo de metadatos incluidos:\n",
      "   üìÑ P√°gina: 1\n",
      "   üî¢ Chunk en p√°gina: 0\n",
      "   üÜî ID: page_1_chunk_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opcional: Subir a Pinecone\n",
    "subir_vectores_a_pinecone(resultado, pc, \"efisys-wiki-knowledge\", namespace=\"dev-pdf-docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc67e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hellou",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
